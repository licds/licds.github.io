<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Yi Li</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">
				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#intro" class="active">About Me</a></li>
							<li><a href="#first">Research and Projects</a></li>
							<li><a href="#second">Selected Coursework</a></li>
							<!-- <li><a href="#cta"></a></li> -->
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="intro" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Yi Li</h2>
										</header>
										<p>Thanks for stopping by! </p>
										<p>I am a fourth-year student at Boston College, double majoring in Computer Science and Management. I am currently taking a gap year (Spring 23' - Spring 24') to pursue my passion in academic research. 
											My research interests include the application of deep learning and computer vision for social goods such as in healthcare (in-home health, medical image analysis) and in personalized education.</p>
										<p>Visit my paper reading blog @ <a href="https://sugar-plum-6f2.notion.site/BLOG-Paper-Reading-Reflections-09705b7028d74328ac1486dc9c33227f" target="_blank" rel="noopener noreferrer">Notion</a></p>
										<p>Email: licds AT bc DOT edu</p>
										<ul class="icons">
											<li><a href="https://github.com/licds" class="icon brands fa-github alt" target="_blank" rel="noopener noreferrer"><span class="label"></span></a></li>
											<li><a href="https://www.linkedin.com/in/yili2023/" class="icon brands fa-linkedin alt" target="_blank" rel="noopener noreferrer"><span class="label"></span></a></li>
											<li><a href="YiLi_CV.pdf" download="YiLi_CV" class="icon regular fa-file-pdf alt" target="_blank" rel="noopener noreferrer"><span class="label"></span></a></li>
										</ul>
									</div>
									<span class="image"><img src="images/Yi.jpg" alt="" /></span>
								</div>
							</section>

						<!-- First Section -->
							<section id="first" class="main">
								<!-- Research Experience -->
								<header class="major">
									<h2>Research</h2>
								</header>

								<h2>Deep Learning for Ultrasound Image Analysis: Assessing Growth and Nutrition</h2>
								<p>Advised by <a href="https://bryanranger.com" target="_blank" rel="noopener noreferrer">Prof. Bryan Ranger</a>, I label phantom data and apply deep learning techniques such as Attention U-Net to segment muscles and measure their thickness. Our current goal is to investigate the correlation between muscle thickness and growth pace of children. We are also seeking approaches to initiate a potential foundation model for ultrasound image analysis.</p>
								<img src="images/AUNet_Rectus.png" width="50%"/>
								<p><a href="https://www.ranger-lab.com" target="_blank" rel="noopener noreferrer">[Ranger Lab]</a></p>
	
								<h2>Incremental Topological Sort</h2>
								<p>Advised by <a href="https://sites.google.com/site/distributedhsinhao/" target="_blank" rel="noopener noreferrer">Prof. Hsin-Hao Su</a>, I built and executed a testing program to examine the correctness and speed of the algorithm. The program expedites the previous testing approach by 12 times, providing valuable insights into the algorithm's performance and capabilities for further investigation.</p>
								<img src="images/incremental_topological_sort_chart.png" width="50%"/>
								<p><a href="https://github.com/licds/Incremental-Topological-Sort-Program" target="_blank" rel="noopener noreferrer">[Code]</a></p>
								
								<!-- Course Projects -->
								<header class="major">
									<h2>Course Projects</h2>
								</header>
							
								<h2>Comparative Analysis on Different Models with HC18 Challenge</h2>
								<p>Advised by <a href="https://donglaiw.github.io/" target="_blank" rel="noopener noreferrer">Prof. Donglai Wei</a>, we examined multiple variants of UNet such as Attention UNet and UNet++ on fetal head segmentation and attempted to replicate the best results in the <a href="https://hc18.grand-challenge.org/" target="_blank" rel="noopener noreferrer">HC18 competition</a>.</p>
								<img src="images/HC18.png" width="50%"/>
								<p><a href="https://drive.google.com/file/d/1QAUy0AHKfoE5r9ijcexsAAm1u1mjAjPS/view?usp=sharing" target="_blank" rel="noopener noreferrer">[Paper]</a> 
									<a href="https://github.com/licds/HC18Challenge" target="_blank" rel="noopener noreferrer">[Code]</a>
								</p>
								
								<h2>MBTI Personality Classification with Performance Assessment</h2>
								<p>Advised by <a href="http://cs.bc.edu/~prudhome/" target="_blank" rel="noopener noreferrer">Prof. Emily Prud'hommeaux</a>, we aimed to identify a person's MBTI personality type from the person's text. Our study found that logistic regression was most accurate in predicting the E/I and F/T personality pairs, with an accuracy rate of 58.4% and 62.1%, respectively. On the other hand, DistilBERT performed best in predicting the N/S and J/P personality pairs, with an accuracy rate of 73.8% and 71.6%, respectively. </p>
								<img src="images/MBTI.png" width="50%"/>
								<p><a href="https://drive.google.com/file/d/1dBdo59eCLoBTaEMmXoOq_XMLVyUAHZBe/view?usp=sharing" target="_blank" rel="noopener noreferrer">[Poster]</a>
									<a href="https://github.com/YifanZhou1999/NLP_project_Fall_22" target="_blank" rel="noopener noreferrer">[Code]</a>
								</p>
								
								<h2>Textual Emotion Detection with Deep Learning and Probablitic Approaches</h2>
								<p>Advised by <a href="https://www.mctague.org/carl/" target="_blank" rel="noopener noreferrer">Prof. Carl McTague</a>, we implemented an interactive webpage to detect emotions (sadness, joy, love, anger, fear, surprise) from user input text, utilizing a dataset of 14,000 sentences for model training. Our best result is a 84.5% accuracy through a Bayes model with modified TF-IDF.</p>
								<img src="images/emo.png" width="50%"/>
								<p><a href="https://github.com/licds/TextualEmotionDetection" target="_blank" rel="noopener noreferrer">[Code]</a></p>
							
							</section>

						<!-- Second Section -->
							<section id="second" class="main">
								<!-- Selected Coursework -->
								<header class="major">
									<h2>Selected Coursework</h2>
								</header>
								<li>Computer Vision</li>
								<li>Natural Language Processing</li>
								<li>Computer Systems</li>
								<li>Algorithms</li>
								<li>Randomness and Computation</li>
								<li>Logic and Computation</li>
								<li>Swift iOS App Development</li>
								<li>Computer Organization and Lab</li>
								<li>Probablity</li>
								<li>Intro to Abstract Math</li>
								<li>Linear Algebra</li>
								<li>Multivariable Calculus</li>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Template by <a href="https://twitter.com/ajlkn">@ajlkn</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
		<!-- VISA Tracking Code for licds.github.io -->
		<script>(function(v,i,s,a,t){v[t]=v[t]||function(){(v[t].v=v[t].v||[]).push(arguments)};if(!v._visaSettings){v._visaSettings={}}v._visaSettings[a]={v:'1.0',s:a,a:'1',t:t};var b=i.getElementsByTagName('body')[0];var p=i.createElement('script');p.defer=1;p.async=1;p.src=s+'?s='+a;b.appendChild(p)})(window,document,'//app-worker.visitor-analytics.io/main.js','03e74b4d-bd78-11ed-b589-901b0edac50a','va')</script><!-- VISA Tracking Code for licds.github.io -->
	</body>
</html>